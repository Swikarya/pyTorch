{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Tensors\n","**Tensors** are used to represent data in neural networks. Real world information are encoded into tensors for the computer and neural network to work on.\n","\n","The main advantage of using tensors is their ability to make use of hardware acceleration provided by GPUs and TPUs that are able to perform large sets of calculations efficiently by allowing for parallel processing."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import torch\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt"]},{"cell_type":"markdown","metadata":{},"source":["After having imported all the necessary libraries, let's check for the version of PyTorch installed in the system."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["print(torch.__version__)"]},{"cell_type":"markdown","metadata":{},"source":["## Creating Tensors\n","\n","All the data stored an utilized in pytorch are stored as tensors. PyTorch tensors are created using **torch.tensor()**\n","\n","Tensors are of several types and one of the classification is made on the basis of the rank of the tensor. They are:\n","\n","*   Rank 0 Tensors (No basis vectors utilized -- **Scalars**)\n","*   Rank 1 Tensors (One basis vector for each direction -- **Vectors**)\n","*   Rank 2 Tensors (Two basis vector for each direction)\n","*   Rank 3 Tensors (Three basis vectors for each direction)"]},{"cell_type":"markdown","metadata":{},"source":["### Scalars"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Creating scalars.\n","# Scalars are tensors of rank 0\n","SCALAR =  torch.tensor(7) # Returns a pytorch tensor with no \"autograd history\" --> look into autograd mechanics\n","torch.is_tensor(SCALAR) # Returns True if the passed object is a PyTorch tensor\n","print(SCALAR.ndim)# Returns the number of dimensions of ndarray in python\n","print(SCALAR.shape)# --> Look into it\n","SCALAR.item() # Returns the item in the scalar (tensor of rank 0) as a regular python integer"]},{"cell_type":"markdown","metadata":{},"source":["### Vectors"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Vectors are created similar to scalars\n","VECTOR = torch.tensor([7,7])\n","print(VECTOR.ndim)\n","print(VECTOR.shape)"]},{"cell_type":"markdown","metadata":{},"source":["### Matrices"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Matrices are created as\n","MATRIX = torch.tensor([[1,2], [3,4]])\n","print(MATRIX.ndim)\n","print(MATRIX.shape)\n","print(MATRIX[0])"]},{"cell_type":"markdown","metadata":{},"source":["### Tensors"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["TENSOR = torch.tensor([[[1,2,3],[4,5,6],[7,8,9]],[[10,11,12],[13,14,15],[16,17,18]],[[19,20,21],[22,23,24],[25,26,27]],[[28,29,30],[31,32,33],[34,35,36]]])\n","print(TENSOR.ndim)\n","print(TENSOR.shape)\n","print(TENSOR[1][2][1])"]},{"cell_type":"markdown","metadata":{},"source":["### Random Tensors\n","\n","Random tensors are useful because neural networks usually start with a random collection of data and then tune them to better fit the problem's solution.\n","Manually initializing tensors that may contain thousands of data is impracical"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Creating a random tensor of size (3,5,2)\n","random = torch.rand(3,5,2)\n","print(random.ndim)\n","print(random.shape)\n","# Creating a tensor of shape similar to an image tensor\n","random_image = torch.tensor(size = ())"]}],"metadata":{"kernelspec":{"display_name":"base","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.11.5"}},"nbformat":4,"nbformat_minor":2}
