{"cells":[{"cell_type":"markdown","metadata":{},"source":["# **Tensors**\n","**Tensors** are used to represent data in neural networks. Real world information are encoded into tensors for the computer and neural network to work on.\n","\n","The main advantage of using tensors is their ability to make use of hardware acceleration provided by GPUs and TPUs that are able to perform large sets of calculations efficiently by allowing for parallel processing."]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["import torch\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","\n","# Remember to include this line at the beginning of every .ipynb file to allow for the console to show all outputs from line evaluations and not just the last one\n","from IPython.core.interactiveshell import InteractiveShell\n","InteractiveShell.ast_node_interactivity = \"all\"\n"]},{"cell_type":"markdown","metadata":{},"source":["After having imported all the necessary libraries, let's check for the version of PyTorch installed in the system."]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[{"data":{"text/plain":["'2.1.0+cpu'"]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["torch.__version__"]},{"cell_type":"markdown","metadata":{},"source":["## Creating Tensors\n","\n","All the data stored an utilized in pytorch are stored as tensors. PyTorch tensors are created using **torch.tensor()**\n","\n","Tensors are of several types and one of the classification is made on the basis of the rank of the tensor. They are:\n","\n","*   Rank 0 Tensors (No basis vectors utilized -- **Scalars**)\n","*   Rank 1 Tensors (One basis vector for each direction -- **Vectors**)\n","*   Rank 2 Tensors (Two basis vector for each direction)\n","*   Rank 3 Tensors (Three basis vectors for each direction)"]},{"cell_type":"markdown","metadata":{},"source":["### Scalars"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[{"data":{"text/plain":["True"]},"execution_count":3,"metadata":{},"output_type":"execute_result"},{"data":{"text/plain":["0"]},"execution_count":3,"metadata":{},"output_type":"execute_result"},{"data":{"text/plain":["torch.Size([])"]},"execution_count":3,"metadata":{},"output_type":"execute_result"},{"data":{"text/plain":["7"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["# Creating scalars.\n","# Scalars are tensors of rank 0\n","SCALAR =  torch.tensor(7) # Returns a pytorch tensor with no \"autograd history\" --> look into autograd mechanics\n","torch.is_tensor(SCALAR) # Returns True if the passed object is a PyTorch tensor\n","SCALAR.ndim# Returns the number of dimensions of ndarray in python\n","SCALAR.shape# --> Look into it\n","SCALAR.item() # Returns the item in the scalar (tensor of rank 0) as a regular python integer"]},{"cell_type":"markdown","metadata":{},"source":["### Vectors"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"data":{"text/plain":["1"]},"execution_count":4,"metadata":{},"output_type":"execute_result"},{"data":{"text/plain":["torch.Size([2])"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["# Vectors are created similar to scalars\n","VECTOR = torch.tensor([7,7])\n","VECTOR.ndim\n","VECTOR.shape"]},{"cell_type":"markdown","metadata":{},"source":["### Matrices"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"data":{"text/plain":["2"]},"execution_count":5,"metadata":{},"output_type":"execute_result"},{"data":{"text/plain":["torch.Size([2, 3])"]},"execution_count":5,"metadata":{},"output_type":"execute_result"},{"data":{"text/plain":["tensor([1, 2, 3])"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["# Matrices are created as\n","MATRIX = torch.tensor([[1,2,3], [3,4,5]])\n","MATRIX.ndim\n","MATRIX.shape\n","MATRIX[0]"]},{"cell_type":"markdown","metadata":{},"source":["### Tensors"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"data":{"text/plain":["3"]},"execution_count":6,"metadata":{},"output_type":"execute_result"},{"data":{"text/plain":["torch.Size([4, 3, 3])"]},"execution_count":6,"metadata":{},"output_type":"execute_result"},{"data":{"text/plain":["tensor(17)"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["TENSOR = torch.tensor([[[1,2,3],[4,5,6],[7,8,9]],[[10,11,12],[13,14,15],[16,17,18]],[[19,20,21],[22,23,24],[25,26,27]],[[28,29,30],[31,32,33],[34,35,36]]])\n","TENSOR.ndim\n","TENSOR.shape\n","TENSOR[1][2][1]"]},{"cell_type":"markdown","metadata":{},"source":["### Random Tensors\n","\n","Random tensors are useful because neural networks usually start with a random collection of data and then tune them to better fit the problem's solution.\n","Manually initializing tensors that may contain thousands of data is impracical"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"data":{"text/plain":["0.8562103509902954"]},"execution_count":7,"metadata":{},"output_type":"execute_result"},{"data":{"text/plain":["3"]},"execution_count":7,"metadata":{},"output_type":"execute_result"},{"data":{"text/plain":["torch.Size([5, 3, 4])"]},"execution_count":7,"metadata":{},"output_type":"execute_result"},{"name":"stdout","output_type":"stream","text":["torch.Size([244, 244, 3]) 3\n"]}],"source":["# Creating a random tensor of size (3,5,2)\n","random = torch.rand(5,3,4)\n","random[3][1][3].item()\n","random.ndim\n","random.shape\n","# Creating a tensor of shape similar to an image tensor\n","random_image = torch.rand(size = (244,244,3)) # Height, width and color channels\n","print(random_image.shape, random_image.ndim)"]},{"cell_type":"markdown","metadata":{},"source":["### Zeros and Ones\n","\n","The .zeros() method creates a tensor of required shape made up entirely of zeros. Tensors with only zeros and ones are used as masks to separate certain region of interest in an image. The .ones() method does the same thing but for ones for all elements."]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[{"data":{"text/plain":["tensor([[[0.3840, 0.9358, 0.4426, 0.4570],\n","         [0.0120, 0.4297, 0.1219, 0.1362],\n","         [0.2816, 0.9538, 0.2088, 0.0590]],\n","\n","        [[0.0042, 0.1471, 0.3352, 0.2698],\n","         [0.9836, 0.0422, 0.7818, 0.9975],\n","         [0.4931, 0.7928, 0.6911, 0.0639]],\n","\n","        [[0.2175, 0.1050, 0.3480, 0.8306],\n","         [0.8441, 0.1273, 0.6889, 0.6670],\n","         [0.2033, 0.3733, 0.5263, 0.4665]],\n","\n","        [[0.4465, 0.3108, 0.3591, 0.0025],\n","         [0.2322, 0.6358, 0.4328, 0.8562],\n","         [0.3317, 0.8527, 0.7063, 0.2345]],\n","\n","        [[0.0767, 0.9674, 0.5421, 0.2370],\n","         [0.4688, 0.4940, 0.0684, 0.0550],\n","         [0.5761, 0.2893, 0.9048, 0.4618]]])"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["ZEROS = torch.zeros(size = (5,10,10))\n","ONES = torch.ones(size = (5,3,4))\n","# print(ZEROS, ONES)\n","\n","# Notes that T1 * T2  where T1 and T2 are tensors performs a simple correspondent element multiplication. So,\n","# print(random * ZEROS)\n","\n","try:\n","  ONES*random\n","except RuntimeError:\n","  print(\"Mismatched Dimension\") # AS the code clearly explains"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[{"data":{"text/plain":["torch.float32"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["ZEROS.dtype"]},{"cell_type":"markdown","metadata":{},"source":["### Range of tensors & tensor-like\n","\n",".arange() returns a rank 2 tensor with elements ranging from start (inclusive) to end (exclusive) with steps (1 by default)"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[{"data":{"text/plain":["tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n","        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n","        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n","        54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71,\n","        72, 73, 74, 75, 76, 77])"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["range = torch.arange(start=0, end=78) # .arange() is left inclusive and right exclusive\n","range"]},{"cell_type":"markdown","metadata":{},"source":[".zeros_like() returns a tensor of shape same as that of input but with each element zero .ones_like() works in a similar way but for ones and .rand_like() for random values"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[{"data":{"text/plain":["tensor([[[0.1682, 0.9584, 0.5182, 0.8582],\n","         [0.1351, 0.7625, 0.8064, 0.3467],\n","         [0.8004, 0.9544, 0.8159, 0.9838]],\n","\n","        [[0.9247, 0.9132, 0.5023, 0.0025],\n","         [0.1865, 0.2317, 0.4969, 0.7124],\n","         [0.2173, 0.3090, 0.5018, 0.9604]],\n","\n","        [[0.8642, 0.3839, 0.7381, 0.1736],\n","         [0.0307, 0.3168, 0.0526, 0.9932],\n","         [0.7912, 0.8032, 0.4988, 0.1782]],\n","\n","        [[0.8176, 0.6464, 0.2367, 0.0263],\n","         [0.9104, 0.0308, 0.2843, 0.5979],\n","         [0.2447, 0.4871, 0.0436, 0.1283]],\n","\n","        [[0.6814, 0.1857, 0.6835, 0.4018],\n","         [0.2664, 0.0833, 0.3682, 0.2783],\n","         [0.2392, 0.1751, 0.1813, 0.5751]]])"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["tens_zeroes_like = torch.rand_like(input=random)\n","tens_zeroes_like"]},{"cell_type":"markdown","metadata":{},"source":["## Tensor datatypes\n","\n","Tensors in PyTorch by default store data in float_32 dtype unless explicitly initialized ie. .rand(), .zeroes(), .ones(), and .rand_like() return a tensor of dtype float_32. The major error points while coding with PyTorch are:\n","*  selection of datatypes \n","*  wrong tensor dimensions \n","*  tensors not on the right device\n","\n","While initializing tensors we can pass params like:\n","*  dtype: datatype of tensor (torch.floa32 / torch.float64)\n","*  device: which device is the tensor on or associated with GPU or CPU\n","*  requires_grad: if PyTorch should track the gradients of the tensor while it is computed on"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[{"data":{"text/plain":["tensor([0.7637, 0.1203, 0.8885], dtype=torch.float64)"]},"execution_count":12,"metadata":{},"output_type":"execute_result"},{"data":{"text/plain":["tensor([3., 6., 9.])"]},"execution_count":12,"metadata":{},"output_type":"execute_result"},{"data":{"text/plain":["torch.float32"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["float_32 = torch.tensor([3.0,6.0,9.0], dtype=None, device=None, requires_grad=False)\n","new = torch.rand_like(input=float_32, dtype=torch.float64)\n","new\n","float_32\n","float_32.dtype"]},{"cell_type":"markdown","metadata":{},"source":["### .dtype \n","\n","is the property of tensor that represents the type of data stored in the tensor"]},{"cell_type":"markdown","metadata":{},"source":["### Typecasting\n","\n","Explicit typecasting is done by .type() method"]},{"cell_type":"code","execution_count":31,"metadata":{},"outputs":[{"data":{"text/plain":["torch.float16"]},"execution_count":31,"metadata":{},"output_type":"execute_result"}],"source":["float_16 = float_32.type(torch.float16)\n","float_16.dtype"]},{"cell_type":"markdown","metadata":{},"source":["Here we see that the result is implicitly typecasted to be float32\n","\n","> Note that the .type() method returns the typecasted tensor and so the returned tensor has to be assigned to some other new tensor or the original tensor"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[{"data":{"text/plain":["torch.float32"]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["result = float_16 * float_32\n","result.dtype"]},{"cell_type":"markdown","metadata":{},"source":["Tensor attributes can be fetched as:\n","*  datatype: tensor.dtype\n","*  device: tensor.device\n","*  shape: tensor.shape | can also use tensor.size(). While shape is a property, size is a method"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[{"data":{"text/plain":["torch.float32"]},"execution_count":15,"metadata":{},"output_type":"execute_result"},{"data":{"text/plain":["torch.Size([3])"]},"execution_count":15,"metadata":{},"output_type":"execute_result"},{"data":{"text/plain":["torch.Size([3])"]},"execution_count":15,"metadata":{},"output_type":"execute_result"},{"data":{"text/plain":["device(type='cpu')"]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["result.dtype\n","result.shape\n","result.size()\n","result.device"]},{"cell_type":"markdown","metadata":{},"source":[".to() method can change the tensor attributes like device and dtype"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[],"source":["# result.to(device=\"cuda\", dtype=torch.float64)"]},{"cell_type":"markdown","metadata":{},"source":["## Tensor Manipulation\n","\n","Tensors can be operated on as:\n","* Addition\n","* Subtraction\n","* Multiplication (element-wise)\n","* Division\n","* Matrix multiplication"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[{"data":{"text/plain":["tensor([[[ 8,  9, 10],\n","         [11, 12, 13]]])"]},"execution_count":17,"metadata":{},"output_type":"execute_result"},{"data":{"text/plain":["tensor([[[-11, -10,  -9],\n","         [ -8,  -7,  -6]]])"]},"execution_count":17,"metadata":{},"output_type":"execute_result"},{"data":{"text/plain":["tensor([[[0.2000, 0.4000, 0.6000],\n","         [0.8000, 1.0000, 1.2000]]])"]},"execution_count":17,"metadata":{},"output_type":"execute_result"}],"source":["test = torch.tensor([[[1,2,3],[4,5,6]]], dtype=torch.long)\n","\n","# Addition\n","test + 7\n","\n","# Multiplication\n","new_test = test * 4\n","\n","# Subtraction\n","test - 12\n","\n","# Division\n","test / 5"]},{"cell_type":"markdown","metadata":{},"source":["Tensors are multiplied in two ways:\n","\n","* Multiplication with a scalar (*)\n","* Matrix Multiplication (@)\n"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([[[1, 2, 3],\n","         [4, 5, 6]]]) * tensor([[[ 4,  8, 12],\n","         [16, 20, 24]]]) = tensor([[[  4,  16,  36],\n","         [ 64, 100, 144]]])\n","mat1 and mat2 shapes cannot be multiplied (2x3 and 2x2)\n"]}],"source":["# Scalar multiplication\n","print(f\"{test} * {new_test} = {test * new_test}\")\n","\n","# Matrix multiplication\n","# torch.matmul(test, new_test)\n","\n","d1 = torch.tensor([[1,2,3],[4,5,6]])\n","d2 = torch.tensor([[1,2],[3,4]])\n","try:\n","  torch.matmul(d1,d2)\n","except Exception as exp:\n","  print(exp)"]},{"cell_type":"markdown","metadata":{},"source":["One of the most frequent errors faced while working with neural networks and writing deep learning code is the size mismatch of tensors that are being multiplied. \n","\n","The two important rules followed are:\n","\n","1. The inner dimensions must match:\n","  * `(3,2) @ (2,3)` will work\n","  * `(3,2) @ (3,2)` won't work\n","  * `(2,3) @ (3,2)` will work\n","  \n","2. The resulting matrix will have the shape of outer dimensions\n","\n",">Note: inner dimensions for (5,7) and (4,6) are (5,4) and outer dimensions are (7,6)"]},{"cell_type":"markdown","metadata":{},"source":["## Tensor Aggregation\n","\n","We can find the max, min, sum, avg of a tensor by using tensor aggregation methods."]},{"cell_type":"code","execution_count":53,"metadata":{},"outputs":[{"data":{"text/plain":["tensor([[[10, 64, 40],\n","         [93, 34, 57],\n","         [35, 73, 30]],\n","\n","        [[74, 98, 27],\n","         [32, 72, 99],\n","         [24, 61, 50]],\n","\n","        [[ 7, 53, 65],\n","         [77, 16,  0],\n","         [39, 62, 78]]], dtype=torch.int16)"]},"execution_count":53,"metadata":{},"output_type":"execute_result"},{"data":{"text/plain":["torch.int16"]},"execution_count":53,"metadata":{},"output_type":"execute_result"}],"source":["random_tensor = torch.rand([3,3,3]) * 100\n","random_tensor = random_tensor.type(torch.int16) # Refer to the note in explicit typecasting section\n","random_tensor\n","random_tensor.dtype"]},{"cell_type":"code","execution_count":56,"metadata":{},"outputs":[{"data":{"text/plain":["tensor(0, dtype=torch.int16)"]},"execution_count":56,"metadata":{},"output_type":"execute_result"},{"data":{"text/plain":["tensor(99, dtype=torch.int16)"]},"execution_count":56,"metadata":{},"output_type":"execute_result"},{"name":"stdout","output_type":"stream","text":["Tensor must be of dtype float or complex and not integer\n"]},{"data":{"text/plain":["tensor(1370)"]},"execution_count":56,"metadata":{},"output_type":"execute_result"},{"data":{"text/plain":["tensor(23)"]},"execution_count":56,"metadata":{},"output_type":"execute_result"},{"data":{"text/plain":["tensor(14)"]},"execution_count":56,"metadata":{},"output_type":"execute_result"}],"source":["# Finding min\n","random_tensor.min()\n","\n","# Finding max\n","random_tensor.max()\n","\n","# Finding mean\n","try:\n","  random_tensor.mean()\n","except RuntimeError:\n","  print(\"Tensor must be of dtype float or complex and not integer\")\n","\n","# Finding sum\n","random_tensor.sum()\n","\n","# Finding the positional min\n","random_tensor.argmin()\n","\n","# Finding the positional max\n","random_tensor.argmax()"]},{"cell_type":"markdown","metadata":{},"source":["> Note that the .argmin() and .argmax() methods return the position of the min and max value assuming that the tensor is one dimensional ie. In a 3x3x3 tensor if the element of index `[1][2][1]` is min then the value returned by the method will be 16. We can see that the reasoning behind the result is that position is counted as 8 when we reach `[0][2][2]` from `[0][0][0]` and continue as 9 for `[1][0][0]`"]}],"metadata":{"kernelspec":{"display_name":"base","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"}},"nbformat":4,"nbformat_minor":2}
